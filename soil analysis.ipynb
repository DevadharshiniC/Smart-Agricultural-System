{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8defa817",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.layers import Dropout, MaxPooling2D, AveragePooling2D, Dense, Flatten, Input, Conv2D, add, Activation\n",
    "from tensorflow.keras.layers import (Dense, Dropout, Activation, Flatten, Reshape, Layer,\n",
    "                          BatchNormalization, LocallyConnected2D,\n",
    "                          ZeroPadding2D, Conv2D, MaxPooling2D, Conv2DTranspose,\n",
    "                          GaussianNoise, UpSampling2D, Input)\n",
    "\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.models import Sequential , Model , load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img , img_to_array , ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5734318f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16,(3,3),activation = \"relu\" , input_shape = (180,180,3)) ,\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(32,(3,3),activation = \"relu\") ,  \n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64,(3,3),activation = \"relu\") ,  \n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(128,(3,3),activation = \"relu\"),  \n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(), \n",
    "    tf.keras.layers.Dense(550,activation=\"relu\"),      #Adding the Hidden layer\n",
    "    tf.keras.layers.Dropout(0.1,seed = 2019),\n",
    "    tf.keras.layers.Dense(400,activation =\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.3,seed = 2019),\n",
    "    tf.keras.layers.Dense(300,activation=\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.4,seed = 2019),\n",
    "    tf.keras.layers.Dense(200,activation =\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.2,seed = 2019),\n",
    "    tf.keras.layers.Dense(5,activation = \"softmax\")   #Adding the Output Layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e056b195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 178, 178, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 89, 89, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 87, 87, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 43, 43, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 41, 41, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 20, 20, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 18, 18, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 9, 9, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 10368)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 550)               5702950   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 550)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 400)               220400    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 400)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 300)               120300    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 300)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 200)               60200     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 5)                 1005      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,202,295\n",
      "Trainable params: 6,202,295\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cca71a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop,SGD,Adam\n",
    "adam=Adam(lr=0.001)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbf06834",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=5     #Setting batch size\n",
    "train_dir = r\"C:\\Users\\devad\\Desktop\\smart agriculture\\half\\Soil types\"\n",
    "validation_dir = r\"C:\\Users\\devad\\Desktop\\smart agriculture\\half\\Soil types\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dcd5028",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Black Soil', 'Cinder Soil','Laterite Soil','Peat Soil','Yellow Soil']\n",
    "img_size = 224\n",
    "def get_data(data_dir):\n",
    "    data = [] \n",
    "    for label in labels: \n",
    "        path = os.path.join(data_dir, label)\n",
    "        class_num = labels.index(label)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_arr = cv2.imread(os.path.join(path, img))[...,::-1] #convert BGR to RGB format\n",
    "                resized_arr = cv2.resize(img_arr, (img_size, img_size)) # Reshaping images to preferred size\n",
    "                data.append([resized_arr, class_num])\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    \n",
    "        train = get_data(r'C:\\Users\\devad\\Desktop\\smart agriculture\\half\\Soil types')\n",
    "        val = get_data(r'C:\\Users\\devad\\Desktop\\smart agriculture\\half\\Soil types')\n",
    "        return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d92a3fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'plt.figure(figsize = (5,5))\\nplt.imshow(train[1][0])\\nplt.title(labels[train[0][1]])\\n\\n\\nplt.figure(figsize = (5,5))\\nplt.imshow(train[-1][0])\\nplt.title(labels[train[-1][1]])'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''plt.figure(figsize = (5,5))\n",
    "plt.imshow(train[1][0])\n",
    "plt.title(labels[train[0][1]])\n",
    "\n",
    "\n",
    "plt.figure(figsize = (5,5))\n",
    "plt.imshow(train[-1][0])\n",
    "plt.title(labels[train[-1][1]])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fa28a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 156 images belonging to 5 classes.\n",
      "Found 156 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "#Setting testing directory\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
    "# All images will be rescaled by 1./255.\n",
    "train_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
    "test_datagen  = ImageDataGenerator( rescale = 1.0/255. )\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "#Flow_from_directory function lets the classifier directly identify the labels from the name of the directories the image lies in\n",
    "train_generator=train_datagen.flow_from_directory(train_dir,batch_size=bs,class_mode='categorical',target_size=(180,180))\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator =  test_datagen.flow_from_directory(validation_dir,\n",
    "                                                         batch_size=bs,\n",
    "                                                         class_mode  = 'categorical',\n",
    "                                                         target_size=(180,180))\n",
    "\n",
    "x,y = next(train_generator)\n",
    "x.shape # input shape of one record is (331,331,3) , 32: is the batch size\n",
    "\n",
    "a = train_generator.class_indices\n",
    "class_names = list(a.keys()) # storing class/breed names in a list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13c49f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(img, labels):\n",
    "\tplt.figure(figsize=[5, 1])\n",
    "\tfor i in range(5):\n",
    "\t\tplt.subplot(5, 5, i+1)\n",
    "\t\tplt.imshow(img[i])\n",
    "\t\tplt.title(class_names[np.argmax(labels[i])])\n",
    "\t\tplt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22a4c917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x72 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_images(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04f35547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "30/30 - 6s - loss: 1.6294 - acc: 0.2123 - val_loss: 1.5581 - val_acc: 0.3600 - 6s/epoch - 195ms/step\n",
      "Epoch 2/50\n",
      "30/30 - 3s - loss: 1.4295 - acc: 0.3562 - val_loss: 1.1441 - val_acc: 0.4000 - 3s/epoch - 115ms/step\n",
      "Epoch 3/50\n",
      "30/30 - 3s - loss: 1.2554 - acc: 0.4041 - val_loss: 1.0836 - val_acc: 0.4267 - 3s/epoch - 115ms/step\n",
      "Epoch 4/50\n",
      "30/30 - 3s - loss: 1.1679 - acc: 0.4521 - val_loss: 1.0555 - val_acc: 0.5467 - 3s/epoch - 115ms/step\n",
      "Epoch 5/50\n",
      "30/30 - 3s - loss: 1.0637 - acc: 0.4247 - val_loss: 0.9196 - val_acc: 0.4800 - 3s/epoch - 115ms/step\n",
      "Epoch 6/50\n",
      "30/30 - 3s - loss: 1.0308 - acc: 0.4247 - val_loss: 0.9910 - val_acc: 0.4400 - 3s/epoch - 115ms/step\n",
      "Epoch 7/50\n",
      "30/30 - 4s - loss: 1.0321 - acc: 0.4452 - val_loss: 1.0127 - val_acc: 0.5533 - 4s/epoch - 117ms/step\n",
      "Epoch 8/50\n",
      "30/30 - 4s - loss: 0.9464 - acc: 0.5342 - val_loss: 0.9967 - val_acc: 0.6600 - 4s/epoch - 117ms/step\n",
      "Epoch 9/50\n",
      "30/30 - 4s - loss: 1.0489 - acc: 0.4452 - val_loss: 0.8750 - val_acc: 0.6267 - 4s/epoch - 120ms/step\n",
      "Epoch 10/50\n",
      "30/30 - 4s - loss: 0.8865 - acc: 0.5959 - val_loss: 0.7208 - val_acc: 0.6067 - 4s/epoch - 129ms/step\n",
      "Epoch 11/50\n",
      "30/30 - 4s - loss: 0.8701 - acc: 0.5890 - val_loss: 0.7684 - val_acc: 0.6467 - 4s/epoch - 129ms/step\n",
      "Epoch 12/50\n",
      "30/30 - 4s - loss: 0.9003 - acc: 0.5890 - val_loss: 0.7914 - val_acc: 0.6267 - 4s/epoch - 137ms/step\n",
      "Epoch 13/50\n",
      "30/30 - 4s - loss: 0.9639 - acc: 0.5205 - val_loss: 0.6334 - val_acc: 0.6600 - 4s/epoch - 142ms/step\n",
      "Epoch 14/50\n",
      "30/30 - 4s - loss: 0.7774 - acc: 0.6507 - val_loss: 0.6358 - val_acc: 0.7200 - 4s/epoch - 128ms/step\n",
      "Epoch 15/50\n",
      "30/30 - 4s - loss: 0.7427 - acc: 0.6849 - val_loss: 0.6437 - val_acc: 0.8000 - 4s/epoch - 128ms/step\n",
      "Epoch 16/50\n",
      "30/30 - 4s - loss: 0.7531 - acc: 0.6644 - val_loss: 0.6171 - val_acc: 0.7267 - 4s/epoch - 122ms/step\n",
      "Epoch 17/50\n",
      "30/30 - 4s - loss: 0.6987 - acc: 0.7055 - val_loss: 0.8304 - val_acc: 0.6200 - 4s/epoch - 121ms/step\n",
      "Epoch 18/50\n",
      "30/30 - 4s - loss: 0.6356 - acc: 0.7603 - val_loss: 0.4619 - val_acc: 0.8733 - 4s/epoch - 125ms/step\n",
      "Epoch 19/50\n",
      "30/30 - 4s - loss: 0.5226 - acc: 0.7867 - val_loss: 0.4425 - val_acc: 0.8267 - 4s/epoch - 125ms/step\n",
      "Epoch 20/50\n",
      "30/30 - 4s - loss: 0.5339 - acc: 0.8082 - val_loss: 0.5431 - val_acc: 0.8000 - 4s/epoch - 121ms/step\n",
      "Epoch 21/50\n",
      "30/30 - 4s - loss: 0.6394 - acc: 0.7466 - val_loss: 0.5117 - val_acc: 0.8133 - 4s/epoch - 122ms/step\n",
      "Epoch 22/50\n",
      "30/30 - 4s - loss: 0.8124 - acc: 0.7603 - val_loss: 0.5248 - val_acc: 0.7867 - 4s/epoch - 128ms/step\n",
      "Epoch 23/50\n",
      "30/30 - 4s - loss: 0.8822 - acc: 0.6849 - val_loss: 0.6989 - val_acc: 0.7267 - 4s/epoch - 128ms/step\n",
      "Epoch 24/50\n",
      "30/30 - 4s - loss: 0.6846 - acc: 0.7466 - val_loss: 0.5470 - val_acc: 0.7867 - 4s/epoch - 124ms/step\n",
      "Epoch 25/50\n",
      "30/30 - 4s - loss: 0.9174 - acc: 0.6507 - val_loss: 0.4815 - val_acc: 0.8733 - 4s/epoch - 122ms/step\n",
      "Epoch 26/50\n",
      "30/30 - 4s - loss: 0.5717 - acc: 0.8219 - val_loss: 0.3277 - val_acc: 0.9200 - 4s/epoch - 127ms/step\n",
      "Epoch 27/50\n",
      "30/30 - 4s - loss: 0.5049 - acc: 0.8067 - val_loss: 0.2796 - val_acc: 0.9067 - 4s/epoch - 122ms/step\n",
      "Epoch 28/50\n",
      "30/30 - 4s - loss: 0.5025 - acc: 0.8288 - val_loss: 0.3614 - val_acc: 0.8800 - 4s/epoch - 123ms/step\n",
      "Epoch 29/50\n",
      "30/30 - 4s - loss: 0.4971 - acc: 0.8836 - val_loss: 0.3036 - val_acc: 0.9000 - 4s/epoch - 125ms/step\n",
      "Epoch 30/50\n",
      "30/30 - 4s - loss: 0.3645 - acc: 0.8699 - val_loss: 0.3120 - val_acc: 0.8800 - 4s/epoch - 124ms/step\n",
      "Epoch 31/50\n",
      "30/30 - 4s - loss: 0.3811 - acc: 0.8904 - val_loss: 0.3828 - val_acc: 0.8333 - 4s/epoch - 124ms/step\n",
      "Epoch 32/50\n",
      "30/30 - 4s - loss: 0.4697 - acc: 0.8562 - val_loss: 0.2461 - val_acc: 0.9267 - 4s/epoch - 127ms/step\n",
      "Epoch 33/50\n",
      "30/30 - 4s - loss: 0.1668 - acc: 0.9521 - val_loss: 0.1056 - val_acc: 0.9733 - 4s/epoch - 126ms/step\n",
      "Epoch 34/50\n",
      "30/30 - 4s - loss: 0.1665 - acc: 0.9521 - val_loss: 0.0988 - val_acc: 0.9800 - 4s/epoch - 127ms/step\n",
      "Epoch 35/50\n",
      "30/30 - 4s - loss: 0.1793 - acc: 0.9247 - val_loss: 0.3192 - val_acc: 0.8933 - 4s/epoch - 124ms/step\n",
      "Epoch 36/50\n",
      "30/30 - 4s - loss: 0.5829 - acc: 0.8630 - val_loss: 0.4743 - val_acc: 0.9000 - 4s/epoch - 124ms/step\n",
      "Epoch 37/50\n",
      "30/30 - 4s - loss: 0.3243 - acc: 0.9110 - val_loss: 0.1807 - val_acc: 0.9667 - 4s/epoch - 124ms/step\n",
      "Epoch 38/50\n",
      "30/30 - 4s - loss: 0.2552 - acc: 0.9384 - val_loss: 0.0672 - val_acc: 0.9867 - 4s/epoch - 121ms/step\n",
      "Epoch 39/50\n",
      "30/30 - 4s - loss: 0.2086 - acc: 0.9384 - val_loss: 0.0833 - val_acc: 0.9600 - 4s/epoch - 123ms/step\n",
      "Epoch 40/50\n",
      "30/30 - 4s - loss: 0.7340 - acc: 0.7945 - val_loss: 0.4858 - val_acc: 0.7800 - 4s/epoch - 122ms/step\n",
      "Epoch 41/50\n",
      "30/30 - 4s - loss: 0.5417 - acc: 0.7333 - val_loss: 0.2478 - val_acc: 0.9000 - 4s/epoch - 126ms/step\n",
      "Epoch 42/50\n",
      "30/30 - 4s - loss: 0.2228 - acc: 0.9247 - val_loss: 0.1103 - val_acc: 0.9600 - 4s/epoch - 124ms/step\n",
      "Epoch 43/50\n",
      "30/30 - 4s - loss: 0.4679 - acc: 0.8562 - val_loss: 0.2013 - val_acc: 0.9400 - 4s/epoch - 124ms/step\n",
      "Epoch 44/50\n",
      "30/30 - 4s - loss: 0.2273 - acc: 0.9384 - val_loss: 0.1281 - val_acc: 0.9733 - 4s/epoch - 125ms/step\n",
      "Epoch 45/50\n",
      "30/30 - 4s - loss: 0.1043 - acc: 0.9658 - val_loss: 0.0331 - val_acc: 0.9933 - 4s/epoch - 121ms/step\n",
      "Epoch 46/50\n",
      "30/30 - 4s - loss: 0.0416 - acc: 0.9863 - val_loss: 0.0072 - val_acc: 1.0000 - 4s/epoch - 124ms/step\n",
      "Epoch 47/50\n",
      "30/30 - 4s - loss: 0.0179 - acc: 1.0000 - val_loss: 0.0083 - val_acc: 1.0000 - 4s/epoch - 126ms/step\n",
      "Epoch 48/50\n",
      "30/30 - 4s - loss: 0.5262 - acc: 0.9110 - val_loss: 0.2453 - val_acc: 0.8933 - 4s/epoch - 123ms/step\n",
      "Epoch 49/50\n",
      "30/30 - 4s - loss: 0.2572 - acc: 0.9178 - val_loss: 0.1467 - val_acc: 0.9667 - 4s/epoch - 123ms/step\n",
      "Epoch 50/50\n",
      "30/30 - 4s - loss: 0.1622 - acc: 0.9726 - val_loss: 0.0732 - val_acc: 0.9867 - 4s/epoch - 123ms/step\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    validation_data=validation_generator,\n",
    "                    steps_per_epoch=150 // bs,\n",
    "                    epochs=50,\n",
    "                    validation_steps=150 // bs,\n",
    "                    verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e665738",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c2102e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='model.h5' target='_blank'>model.h5</a><br>"
      ],
      "text/plain": [
       "C:\\Users\\devad\\100% implementation\\notebooks\\model.h5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec783294",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
